{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "import os\n",
    "import json\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###############Query###########################\n",
    "query = \"\"\"PREFIX lm: <http://ontology.lungmap.net/ontologies/expression_ontology#>\n",
    "PREFIX mont: <http://ontology.lungmap.net/ontologies/mouse_anatomy#>\n",
    "PREFIX owl: <http://www.w3.org/2002/07/>\n",
    "PREFIX owl2: <http://www.w3.org/2002/07/owl#>\n",
    "SELECT DISTINCT ?experiment_id ?image_id \n",
    "?path ?raw_file\n",
    "?experiment_type_label ?experiment_type_id\n",
    "?term ?term_label ?experiment\n",
    "FROM  <http://data.lungmap.net/lungmap_data>\n",
    "FROM  <http://data.lungmap.net/lungmap_ontology>\n",
    "FROM  <http://data.lungmap.net/lungmap_ontology>\n",
    "\n",
    "WHERE {\n",
    "   ?experiment_id lm:is_experiment_type/rdfs:label ?experiment_type_label .\n",
    "   ?image_id lm:part_of_experiment ?experiment_id .\n",
    "   ?experiment_id lm:file_name ?path .\n",
    "   ?image_id lm:display_url ?raw_file .\n",
    "   ?experiment_id lm:is_experiment_type ?experiment_type_id .\n",
    "\n",
    "   ?experiment_id lm:has_condition ?term .\n",
    "   ?term rdfs:label ?term_label .\n",
    "\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "\n",
    "sparql = SPARQLWrapper(\"http://testdata.lungmap.net/sparql\")\n",
    "sparql.setQuery(query)\n",
    "sparql.setReturnFormat(JSON)\n",
    "#Here are all the results form the sparql query above\n",
    "results = sparql.query().convert()\n",
    "\n",
    "##############################################################################\n",
    "############################################################################## \n",
    "##############################################################################\n",
    "#len(results['results']['bindings'])\n",
    "index = []\n",
    "#only want to do .tif files (check with Cliburn), so get index of those files\n",
    "for i,x in enumerate(results['results']['bindings']):\n",
    "    filename = x.get('raw_file').get('value')\n",
    "    name, ext = os.path.splitext(filename)\n",
    "    if (ext=='.tif' or ext=='.tiff'):\n",
    "        #print(ext)\n",
    "        index.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tif_files = [results['results']['bindings'][i] for i in index]\n",
    "#Define a client connection to our bucket for download\n",
    "s3 = boto3.resource('s3')\n",
    "bucket = s3.Bucket('lungmap-breath-data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regexp = re.compile(\"#(.*)$\")\n",
    "def bens_dict_2_flatfile(metadata_from_sparql):\n",
    "    #Here are the \"variables that I want in my flat file:\n",
    "    s3downloadkey = [] #I can parse this to get file name if needed and this should be unique by metadata object (primary key)\n",
    "    image_id = []\n",
    "    experiment_id = []\n",
    "    term = []\n",
    "    experiment = []\n",
    "    term_label = []\n",
    "    \n",
    "    for i, x in enumerate(metadata_from_sparql):\n",
    "        #first, I'll create my s3key name\n",
    "        filename = x.get('raw_file').get('value')\n",
    "        name, ext = os.path.splitext(filename)\n",
    "        root = os.path.basename(os.path.normpath(x.get('path').get('value')))\n",
    "        s3objkey =  os.path.join(root,name,filename)\n",
    "        #now let's start appending to our lists\n",
    "        s3downloadkey.append(s3objkey)\n",
    "        \n",
    "        tm = regexp.search(os.path.basename(os.path.normpath(x.get('term').get('value')))).group(1)\n",
    "        term.append(tm)\n",
    "        exp_id = regexp.search(os.path.basename(os.path.normpath(x.get('experiment_type_id').get('value')))).group(1)\n",
    "        experiment_id.append(exp_id)\n",
    "        term_label.append(x.get('term_label').get('value'))\n",
    "        im_id = regexp.search(os.path.normpath(x.get('image_id').get('value'))).group(1)\n",
    "        image_id.append(im_id)\n",
    "        output = pd.DataFrame({  #'s3downloadkey' : s3downloadkey,\n",
    "                             'experiment_id': experiment_id,\n",
    "                             'term_label': term_label,\n",
    "                             'term': term,\n",
    "                             'image_id': image_id\n",
    "                              },index=s3downloadkey)\n",
    "    return(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flat_file = bens_dict_2_flatfile(tif_files[:]) \n",
    "#note that we now have the key to download from boto3\n",
    "#i.e. bucket.download_file(s3objkey, os.path.join(filepath, filename)) \n",
    "#os.chdir('/Users/nn31/Dropbox/40-githubRrepos/lungmap-data-plus-2016/data') \n",
    "flat_file.to_csv('C:/Users/Lina/Desktop/metadata/metadata_dictionary_annotation_terms.csv',index=False)    #this file ends up in os.getcwd()               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LMEX0000000676_IMG_1',\n",
       " 'LMEX0000000675_IMG_4',\n",
       " 'LMEX0000000675_IMG_3',\n",
       " 'LMEX0000000675_IMG_2',\n",
       " 'LMEX0000000675_IMG_5',\n",
       " 'LMEX0000000676_IMG_3',\n",
       " 'LMEX0000000675_IMG_6',\n",
       " 'LMEX0000000676_IMG_4',\n",
       " 'LMEX0000000676_IMG_5',\n",
       " 'LMEX0000000676_IMG_2',\n",
       " 'LMEX0000000675_IMG_1']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_images = pd.read_csv('C:/Users/Lina/Desktop/metadata/00_metadata_dictionary.csv')  \n",
    "new_output = pd.read_csv('C:/Users/Lina/Desktop/metadata/metadata_dictionary_annotation_terms.csv').loc[pd.read_csv('C:/Users/Lina/Desktop/metadata/metadata_dictionary_annotation_terms.csv')['image_id'].isin(our_images.image_id.tolist())]\n",
    "new_output.shape==our_images.shape                   \n",
    "#uh oh, what's going on?\n",
    "list(set(our_images.image_id.tolist()) - set(new_output.image_id.tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
